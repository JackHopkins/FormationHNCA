{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Phase 2: Formation Transitions\n\n**Prerequisite**: Complete `phase1_line_formation.ipynb` first.\n\n**Goal**: Train the NCA to transition between formations based on spatial guidance.\n\n**Training Coverage**:\n- **Formation → Formation** (25 pairs): All pairwise transitions between 5 formations\n- **Seed → Formation** (5 pairs): Gaussian blob to any formation (retains Phase 1 capability)\n\n**Formations**:\n- Line (horizontal band)\n- Phalanx (deep rectangular block)\n- Square (hollow defensive square)\n- Wedge (triangle/arrow)\n- Column (vertical band)\n\n**Key Improvements**:\n- **Alpha-only loss**: Focused gradient on shape channel\n- **Spatial guidance**: Target alpha broadcast as formation signal\n- **Mass conservation**: Maintained during all transitions\n- **Mixed pool**: 80% formations + 20% Gaussian seeds\n\n**Success Criteria**:\n- Formation→Formation: Avg MSE < 0.02, worst < 0.05\n- Seed→Formation: Avg MSE < 0.02, worst < 0.05\n- Mass retention > 85% average, > 70% worst case"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T21:02:44.059853Z",
     "start_time": "2026-01-19T21:02:40.067698Z"
    }
   },
   "source": [
    "# Setup\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/JackHopkins/FormationHNCA.git\"\n",
    "\n",
    "if os.path.exists(\"/content\"):\n",
    "    REPO_DIR = \"/content/FormationHNCA\"\n",
    "elif os.path.exists(\"/workspace\"):\n",
    "    REPO_DIR = \"/workspace/FormationHNCA\"\n",
    "else:\n",
    "    REPO_DIR = os.path.expanduser(\"~/FormationHNCA\")\n",
    "\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"Pulling latest changes in {REPO_DIR}...\")\n",
    "    result = subprocess.run([\"git\", \"-C\", REPO_DIR, \"pull\"], capture_output=True, text=True)\n",
    "    print(result.stdout or \"Already up to date.\")\n",
    "else:\n",
    "    print(f\"Cloning repository to {REPO_DIR}...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "print(\"Installing JAX with CUDA support...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"jax[cuda12]\"], check=True)\n",
    "\n",
    "print(\"Installing battle-nca package...\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", \".\"], check=True)\n",
    "\n",
    "src_path = os.path.join(REPO_DIR, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")\n",
    "print(\"Setup complete!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling latest changes in /workspace/FormationHNCA...\n",
      "Already up to date.\n",
      "\n",
      "Installing JAX with CUDA support...\n",
      "Installing battle-nca package...\n",
      "\n",
      "Working directory: /workspace/FormationHNCA\n",
      "Setup complete!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T21:02:45.374811Z",
     "start_time": "2026-01-19T21:02:44.374972Z"
    }
   },
   "source": [
    "import jax\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "jax.clear_caches()\n",
    "\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "\n",
    "if jax.devices()[0].platform == 'gpu':\n",
    "    print(\"GPU acceleration enabled!\")\n",
    "else:\n",
    "    print(\"WARNING: Running on CPU.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version: 0.8.2\n",
      "JAX devices: [CudaDevice(id=0)]\n",
      "GPU acceleration enabled!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T21:02:48.961435Z",
     "start_time": "2026-01-19T21:02:45.881909Z"
    }
   },
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from battle_nca.core import NCA, perceive\n",
    "from battle_nca.core.nca import create_seed\n",
    "from battle_nca.hierarchy import ChildNCA, ParentNCA, HierarchicalNCA\n",
    "from battle_nca.hierarchy.child_nca import create_army_seed, CHILD_CHANNELS\n",
    "from battle_nca.combat import FormationTargets, create_formation_target, rotate_formation\n",
    "from battle_nca.combat.formations import FormationTypes\n",
    "from battle_nca.training import NCAPool, Trainer, TrainingConfig\n",
    "from battle_nca.training.optimizers import create_optimizer, normalize_gradients\n",
    "\n",
    "print(\"All imports successful!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T21:02:49.369323Z",
     "start_time": "2026-01-19T21:02:49.366287Z"
    }
   },
   "source": [
    "GRID_SIZE = 64\n",
    "NUM_CHANNELS = 24\n",
    "\n",
    "# RESET: Set True to start Phase 2 from Phase 1 checkpoint\n",
    "# Set False to resume Phase 2 training\n",
    "RESET = True\n",
    "\n",
    "config = TrainingConfig(\n",
    "    batch_size=12,\n",
    "    pool_size=1024,\n",
    "    min_steps=128,\n",
    "    max_steps=192,\n",
    "    learning_rate=2e-3,\n",
    "    gradient_clip=1.0,\n",
    "    damage_samples=3,\n",
    "    damage_start_epoch=1000,  # Later damage since transitions are harder\n",
    "    log_interval=10,\n",
    "    checkpoint_interval=100\n",
    ")\n",
    "\n",
    "PHASE2_EPOCHS = 500\n",
    "SEED = 42\n",
    "\n",
    "# Rotation augmentation\n",
    "USE_ROTATION_AUGMENTATION = True\n",
    "ROTATION_CONTINUOUS = True\n",
    "\n",
    "# Checkpoints\n",
    "PHASE1_CHECKPOINT = Path('checkpoints/phase1_line.pkl')\n",
    "PHASE2_CHECKPOINT = Path('checkpoints/phase2_transitions.pkl')\n",
    "PHASE2_CHECKPOINT.parent.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Phase 2: Formation Transitions\")\n",
    "print(f\"Task: Formation A -> Formation B (not seed -> formation)\")\n",
    "print(f\"Steps per transition: {config.min_steps}-{config.max_steps}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2: Formation Transitions\n",
      "Task: Formation A -> Formation B (not seed -> formation)\n",
      "Steps per transition: 128-192\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Phase 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T21:02:49.628999Z",
     "start_time": "2026-01-19T21:02:49.599194Z"
    }
   },
   "source": [
    "child_nca = ChildNCA(\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    hidden_dim=128,\n",
    "    fire_rate=0.5,\n",
    "    use_circular_padding=True,\n",
    "    use_alive_masking=False  # Disabled for Phase 2 - allows mass to grow in empty regions\n",
    ")\n",
    "\n",
    "# Seed for initialization only\n",
    "seed = create_army_seed(\n",
    "    height=GRID_SIZE,\n",
    "    width=GRID_SIZE,\n",
    "    team_color=(1.0, 0.0, 0.0),\n",
    "    unit_type=0,\n",
    "    formation_id=0,\n",
    "    spawn_region=(GRID_SIZE//2 - 2, GRID_SIZE//2 + 2, GRID_SIZE//2 - 2, GRID_SIZE//2 + 2)\n",
    ")\n",
    "\n",
    "print(f\"Seed shape: {seed.shape}\")\n",
    "print(f\"Alive masking: DISABLED (allows transitions through empty regions)\")"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ChildNCA.__init__() got an unexpected keyword argument 'use_alive_masking'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m child_nca = \u001B[43mChildNCA\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mNUM_CHANNELS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_dim\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfire_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_circular_padding\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_alive_masking\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Disabled for Phase 2 - allows mass to grow in empty regions\u001B[39;49;00m\n\u001B[32m      7\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;66;03m# Seed for initialization only\u001B[39;00m\n\u001B[32m     10\u001B[39m seed = create_army_seed(\n\u001B[32m     11\u001B[39m     height=GRID_SIZE,\n\u001B[32m     12\u001B[39m     width=GRID_SIZE,\n\u001B[32m   (...)\u001B[39m\u001B[32m     16\u001B[39m     spawn_region=(GRID_SIZE//\u001B[32m2\u001B[39m - \u001B[32m2\u001B[39m, GRID_SIZE//\u001B[32m2\u001B[39m + \u001B[32m2\u001B[39m, GRID_SIZE//\u001B[32m2\u001B[39m - \u001B[32m2\u001B[39m, GRID_SIZE//\u001B[32m2\u001B[39m + \u001B[32m2\u001B[39m)\n\u001B[32m     17\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/local/lib/python3.12/dist-packages/flax/linen/kw_only_dataclasses.py:235\u001B[39m, in \u001B[36m_process_class.<locals>.init_wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    227\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m num_args > expected_num_args:\n\u001B[32m    228\u001B[39m   \u001B[38;5;66;03m# we add + 1 to each to account for `self`, matching python's\u001B[39;00m\n\u001B[32m    229\u001B[39m   \u001B[38;5;66;03m# default error message\u001B[39;00m\n\u001B[32m    230\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    231\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33m__init__() takes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_num_args\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m positional \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    232\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33marguments but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_args\u001B[38;5;250m \u001B[39m+\u001B[38;5;250m \u001B[39m\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m were given\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    233\u001B[39m   )\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m \u001B[43mdataclass_init\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mTypeError\u001B[39m: ChildNCA.__init__() got an unexpected keyword argument 'use_alive_masking'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "key = jax.random.PRNGKey(SEED)\nkey, init_key = jax.random.split(key)\n\ndef count_params(params):\n    return sum(p.size for p in jax.tree_util.tree_leaves(params))\n\n# Phase 2 trains FROM SCRATCH with 6-channel signal:\n# [target_alpha, flow_x, flow_y, proximity, grad_x, grad_y]\n# This gives explicit \"marching orders\" to cells\n\n# Number of signal channels (must match cell-16)\nINIT_SIGNAL_CHANNELS = 6\n\n# loaded_checkpoint will be used by cell-18 to restore training state\nloaded_checkpoint = None\n\nif RESET:\n    print(\"Initializing FRESH model for Phase 2 (with 6-channel FLOW FIELD signal)...\")\n    \n    # Create a dummy signal with 6 channels for initialization\n    dummy_signal = jnp.zeros((GRID_SIZE, GRID_SIZE, INIT_SIGNAL_CHANNELS))\n    \n    # Initialize fresh parameters\n    params = child_nca.init(init_key, seed, jax.random.PRNGKey(0), parent_signal=dummy_signal)['params']\n    \n    print(f\"  Fresh model initialized with {count_params(params):,} parameters\")\n    print(f\"  Signal channels: {INIT_SIGNAL_CHANNELS}\")\n    print(f\"    [0] Target alpha (what to become)\")\n    print(f\"    [1] Flow X (horizontal marching direction)\")\n    print(f\"    [2] Flow Y (vertical marching direction)\")\n    print(f\"    [3] Proximity (distance to target)\")\n    print(f\"    [4] Target gradient X\")\n    print(f\"    [5] Target gradient Y\")\nelse:\n    if PHASE2_CHECKPOINT.exists():\n        print(f\"Loading Phase 2 checkpoint from {PHASE2_CHECKPOINT}...\")\n        with open(PHASE2_CHECKPOINT, 'rb') as f:\n            loaded_checkpoint = pickle.load(f)\n        \n        params = loaded_checkpoint['params']\n        \n        # Display checkpoint info\n        epochs_done = loaded_checkpoint.get('epoch', len(loaded_checkpoint['metrics'].get('losses', [])))\n        best_loss = loaded_checkpoint.get('best_loss', 'N/A')\n        has_pool = 'pool' in loaded_checkpoint\n        pool_shape = loaded_checkpoint['pool'].shape if has_pool else 'N/A'\n        \n        print(f\"  Loaded Phase 2 model\")\n        print(f\"  Epochs completed: {epochs_done}\")\n        print(f\"  Best loss: {best_loss}\")\n        print(f\"  Pool saved: {has_pool} (shape: {pool_shape})\")\n        print(f\"  Metrics restored: {len(loaded_checkpoint['metrics'].get('losses', []))} loss values\")\n        \n        if has_pool:\n            print(f\"\\n  Training will RESUME from epoch {epochs_done + 1}\")\n        else:\n            print(f\"\\n  WARNING: No pool in checkpoint, will use fresh pool\")\n        \n        # Note: If resuming from old checkpoint with 4-channel signal,\n        # model architecture will be incompatible - need fresh start\n        print(f\"\\n  NOTE: If checkpoint used different signal channels, set RESET=True\")\n    else:\n        print(\"No Phase 2 checkpoint found. Initializing fresh model...\")\n        dummy_signal = jnp.zeros((GRID_SIZE, GRID_SIZE, INIT_SIGNAL_CHANNELS))\n        params = child_nca.init(init_key, seed, jax.random.PRNGKey(0), parent_signal=dummy_signal)['params']\n        print(f\"  Fresh model initialized with {count_params(params):,} parameters\")\n\nprint(f\"\\nTotal parameters: {count_params(params):,}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Formation Targets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create formation targets with IDENTICAL MASS via SIZE SCALING\n# Instead of reducing density, we scale formation dimensions smaller\n# This preserves the characteristic density of each formation type\n\n# First, create raw formations to measure their masses\nraw_targets = {\n    'line': FormationTargets.line(GRID_SIZE, GRID_SIZE),\n    'phalanx': FormationTargets.phalanx(GRID_SIZE, GRID_SIZE, depth=8),\n    'square': FormationTargets.square(GRID_SIZE, GRID_SIZE, thickness=3),\n    'wedge': FormationTargets.wedge(GRID_SIZE, GRID_SIZE),\n    'column': FormationTargets.column(GRID_SIZE, GRID_SIZE, col_width=4),\n}\n\n# Compute masses before normalization\nprint(\"Formation masses (original):\")\nfor name, target in raw_targets.items():\n    mass = float(jnp.sum(target[..., 3]))\n    density = float(jnp.mean(target[..., 3][target[..., 3] > 0.1]))  # Mean of non-zero\n    area = int(jnp.sum(target[..., 3] > 0.1))\n    print(f\"  {name:10s}: mass={mass:>6.1f}, density={density:.2f}, area={area}\")\n\n# Use the SMALLEST mass as reference\nmasses = {name: float(jnp.sum(target[..., 3])) for name, target in raw_targets.items()}\nREFERENCE_MASS = min(masses.values())\nreference_formation = min(masses, key=masses.get)\nprint(f\"\\nReference: {reference_formation} with mass={REFERENCE_MASS:.1f}\")\n\n\ndef scale_formation_to_mass(target, target_mass, grid_size):\n    \"\"\"Scale a formation by resizing it to achieve target mass while preserving density.\n    \n    The formation is scaled down (or up) spatially so that its total mass\n    matches target_mass, without changing the density of filled pixels.\n    \n    Args:\n        target: Formation target (H, W, 4)\n        target_mass: Desired total mass\n        grid_size: Size of the grid\n    \n    Returns:\n        Scaled formation centered in the grid\n    \"\"\"\n    current_mass = jnp.sum(target[..., 3])\n    \n    # Scale factor for dimensions (sqrt because area scales with square)\n    scale = jnp.sqrt(target_mass / (current_mass + 1e-8))\n    \n    if scale >= 0.99:  # Already at or below target mass\n        return target\n    \n    # Compute new dimensions\n    h, w = target.shape[:2]\n    new_h = int(h * scale)\n    new_w = int(w * scale)\n    \n    # Create coordinate grids for the scaled formation\n    center_y, center_x = h / 2, w / 2\n    \n    # Output coordinates\n    y_out, x_out = jnp.meshgrid(\n        jnp.arange(h, dtype=jnp.float32),\n        jnp.arange(w, dtype=jnp.float32),\n        indexing='ij'\n    )\n    \n    # Map to source coordinates (inverse scaling from center)\n    y_src = (y_out - center_y) / scale + center_y\n    x_src = (x_out - center_x) / scale + center_x\n    \n    # Bilinear interpolation\n    y0 = jnp.floor(y_src).astype(jnp.int32)\n    x0 = jnp.floor(x_src).astype(jnp.int32)\n    y1 = y0 + 1\n    x1 = x0 + 1\n    \n    # Clamp to valid range\n    y0_c = jnp.clip(y0, 0, h - 1)\n    y1_c = jnp.clip(y1, 0, h - 1)\n    x0_c = jnp.clip(x0, 0, w - 1)\n    x1_c = jnp.clip(x1, 0, w - 1)\n    \n    # Interpolation weights\n    wy = y_src - y0.astype(jnp.float32)\n    wx = x_src - x0.astype(jnp.float32)\n    \n    # Out of bounds mask\n    in_bounds = (\n        (y_src >= 0) & (y_src < h - 1) &\n        (x_src >= 0) & (x_src < w - 1)\n    )\n    \n    def interpolate_channel(channel_data):\n        v00 = channel_data[y0_c, x0_c]\n        v01 = channel_data[y0_c, x1_c]\n        v10 = channel_data[y1_c, x0_c]\n        v11 = channel_data[y1_c, x1_c]\n        \n        v0 = v00 * (1 - wx) + v01 * wx\n        v1 = v10 * (1 - wx) + v11 * wx\n        v = v0 * (1 - wy) + v1 * wy\n        \n        return jnp.where(in_bounds, v, 0.0)\n    \n    # Apply to all channels\n    scaled = jnp.stack([\n        interpolate_channel(target[..., i])\n        for i in range(target.shape[-1])\n    ], axis=-1)\n    \n    return scaled\n\n\n# Scale all formations to reference mass\ntargets = {}\nfor name, target in raw_targets.items():\n    targets[name] = scale_formation_to_mass(target, REFERENCE_MASS, GRID_SIZE)\n\n# Verify scaling\nprint(\"\\nFormation masses AFTER size scaling:\")\nfor name, target in targets.items():\n    mass = float(jnp.sum(target[..., 3]))\n    density = float(jnp.mean(target[..., 3][target[..., 3] > 0.1])) if jnp.any(target[..., 3] > 0.1) else 0\n    area = int(jnp.sum(target[..., 3] > 0.1))\n    print(f\"  {name:10s}: mass={mass:>6.1f}, density={density:.2f}, area={area}\")\n\nformation_names = list(targets.keys())\nnum_formations = len(formation_names)\n\n# Visualize base formations and rotated versions\nfig, axes = plt.subplots(2, num_formations, figsize=(3*num_formations, 6))\nfor idx, (name, target) in enumerate(targets.items()):\n    mass = float(jnp.sum(target[..., 3]))\n    density = float(jnp.mean(target[..., 3][target[..., 3] > 0.1])) if jnp.any(target[..., 3] > 0.1) else 0\n    \n    # Base formation\n    axes[0, idx].imshow(target[..., 3], cmap='gray', vmin=0, vmax=1)\n    axes[0, idx].set_title(f'{name}\\nmass={mass:.0f}, d={density:.2f}')\n    axes[0, idx].axis('off')\n    \n    # Rotated 45° (worst case for clipping)\n    rotated = rotate_formation(target, np.pi/4)\n    rotated_mass = float(jnp.sum(rotated[..., 3]))\n    axes[1, idx].imshow(rotated[..., 3], cmap='gray', vmin=0, vmax=1)\n    axes[1, idx].set_title(f'rotated 45°\\nmass={rotated_mass:.0f}')\n    axes[1, idx].axis('off')\n\nplt.suptitle(f'Formation Targets (SIZE-SCALED to mass={REFERENCE_MASS:.0f}, density preserved)', fontsize=14)\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nCreated {num_formations} formation targets with IDENTICAL mass via SIZE SCALING\")\nprint(f\"Density is PRESERVED - larger formations are scaled smaller to match mass\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Create Mixed Training Pool\n\nThe pool contains both established formations AND Gaussian seeds:\n- **80% formations**: For Formation A → Formation B transitions\n- **20% Gaussian seeds**: For Seed → Formation transitions (Phase 1 capability)\n\nEach training iteration will:\n1. Sample a starting state (formation OR seed)\n2. Pick a target formation\n3. Train the NCA to transition while conserving mass\n\nThis ensures the model can:\n- Transform between any pair of formations\n- Form any shape from a dispersed blob (robust to damage)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# === BACKGROUND ALPHA FOR GRADIENT FLOW ===\n# Key insight: Empty cells (alpha=0) cannot receive useful gradients because\n# there's nothing to update. By adding a small background alpha everywhere,\n# we provide a gradient path for mass to \"flow\" into new areas.\n#\n# This is critical for formation transitions where the target shape\n# may have mass in locations where the source has none.\n\nBACKGROUND_ALPHA = 0.02  # Small enough to not affect visuals, large enough for gradients\n\n\ndef create_formation_state(target, key):\n    \"\"\"Create an NCA state from a formation target.\n    \n    Converts the target pattern into a full 24-channel state with:\n    - RGB from target\n    - Alpha from target WITH BACKGROUND for gradient flow\n    - Other channels initialized appropriately\n    \"\"\"\n    state = jnp.zeros((GRID_SIZE, GRID_SIZE, NUM_CHANNELS))\n    \n    # Copy RGB from target\n    state = state.at[..., :3].set(target[..., :3])\n    \n    # Alpha with BACKGROUND - enables gradient flow through \"empty\" regions\n    # The background alpha provides a path for mass to grow into new areas\n    alpha_with_bg = jnp.maximum(target[..., 3], BACKGROUND_ALPHA)\n    state = state.at[..., 3].set(alpha_with_bg)\n    \n    # Initialize health where alpha > threshold (ignoring background)\n    alive = target[..., 3] > 0.1\n    state = state.at[..., 4].set(jnp.where(alive, 1.0, 0.0))  # Health\n    state = state.at[..., 5].set(jnp.where(alive, 1.0, 0.0))  # Morale\n    \n    # Small random noise in hidden channels for diversity\n    noise = jax.random.uniform(key, (GRID_SIZE, GRID_SIZE, 9), minval=-0.1, maxval=0.1)\n    state = state.at[..., 15:24].set(noise)\n    \n    return state\n\n\ndef create_gaussian_seed(height, width, num_channels, target_mass, key, sigma=10.0):\n    \"\"\"Create a Gaussian blob seed with specified total mass.\n    \n    Same as Phase 1 - blob centered in grid with alpha values scaled\n    so total mass equals target_mass. Includes background alpha.\n    \"\"\"\n    state = jnp.zeros((height, width, num_channels))\n    \n    # Create Gaussian blob centered in grid\n    cy, cx = height // 2, width // 2\n    y = jnp.arange(height)\n    x = jnp.arange(width)\n    yy, xx = jnp.meshgrid(y, x, indexing='ij')\n    \n    # Gaussian distribution\n    dist_sq = (yy - cy) ** 2 + (xx - cx) ** 2\n    gaussian = jnp.exp(-dist_sq / (2 * sigma ** 2))\n    \n    # Scale to match target mass (accounting for background we'll add)\n    # Subtract background contribution from target\n    bg_mass = height * width * BACKGROUND_ALPHA\n    adjusted_target_mass = max(target_mass - bg_mass, target_mass * 0.5)  # Don't go too low\n    \n    current_mass = jnp.sum(gaussian)\n    alpha = gaussian * (adjusted_target_mass / current_mass)\n    alpha = jnp.clip(alpha, 0.0, 1.0)\n    \n    # Add background alpha for gradient flow\n    alpha_with_bg = jnp.maximum(alpha, BACKGROUND_ALPHA)\n    \n    # Set RGBA channels\n    state = state.at[..., 0].set(1.0)  # R (team color)\n    state = state.at[..., 1].set(0.0)  # G\n    state = state.at[..., 2].set(0.0)  # B\n    state = state.at[..., 3].set(alpha_with_bg)  # Alpha with background\n    \n    # Initialize other channels where alpha > threshold (ignoring background)\n    alive = alpha > 0.1\n    state = state.at[..., CHILD_CHANNELS.HEALTH].set(jnp.where(alive, 1.0, 0.0))\n    state = state.at[..., CHILD_CHANNELS.MORALE].set(jnp.where(alive, 0.5, 0.0))\n    \n    # Small noise in hidden channels\n    key, subkey = jax.random.split(key)\n    hidden_noise = jax.random.uniform(subkey, (height, width, 9), minval=-0.1, maxval=0.1)\n    state = state.at[..., CHILD_CHANNELS.HIDDEN_START:CHILD_CHANNELS.HIDDEN_END].set(\n        jnp.where(alive[..., None], hidden_noise, 0.0)\n    )\n    \n    return state\n\n\n# REFERENCE_MASS: All formations were normalized to identical mass in cell-10\n# This value is used for Gaussian seeds to match formation mass\n# (After normalization, any formation gives the same value)\nprint(f\"Using normalized REFERENCE_MASS = {REFERENCE_MASS:.0f} (all formations have identical mass)\")\nprint(f\"Background alpha = {BACKGROUND_ALPHA} (enables gradient flow through empty cells)\")\n\n# Pool composition: 80% formations, 20% Gaussian seeds\nSEED_FRACTION = 0.2\nSEED_ID = num_formations  # Use index beyond formations to mark seeds\n\n\ndef create_transition_pool(pool_size, key):\n    \"\"\"Create a pool for transition training.\n    \n    Pool contains:\n    - 80% established formations (for Formation A -> Formation B)\n    - 20% Gaussian seeds (for Seed -> Formation, like Phase 1)\n    \n    This ensures the model retains seed->formation capability\n    and is robust to heavily damaged/dispersed states.\n    \n    NOTE: All formations have IDENTICAL mass due to normalization in cell-10.\n    Gaussian seeds are also scaled to this same mass.\n    All states have background alpha for gradient flow.\n    \"\"\"\n    pool_states = []\n    pool_formation_ids = []  # Track which formation each state is (SEED_ID for seeds)\n    \n    num_seeds = int(pool_size * SEED_FRACTION)\n    num_formations_samples = pool_size - num_seeds\n    samples_per_formation = num_formations_samples // num_formations\n    \n    # Add established formations (80%)\n    for formation_idx, name in enumerate(formation_names):\n        target = targets[name]\n        \n        for i in range(samples_per_formation):\n            key, subkey1, subkey2 = jax.random.split(key, 3)\n            \n            # Random rotation for variety\n            if USE_ROTATION_AUGMENTATION:\n                angle = float(jax.random.uniform(subkey1, (), minval=0, maxval=2*jnp.pi))\n                rotated_target = rotate_formation(target, angle)\n            else:\n                rotated_target = target\n            \n            state = create_formation_state(rotated_target, subkey2)\n            pool_states.append(state)\n            pool_formation_ids.append(formation_idx)\n    \n    # Add Gaussian seeds (20%)\n    for i in range(num_seeds):\n        key, subkey = jax.random.split(key)\n        # Vary sigma for different spread levels\n        sigma = float(jax.random.uniform(subkey, (), minval=6.0, maxval=14.0))\n        key, subkey = jax.random.split(key)\n        state = create_gaussian_seed(GRID_SIZE, GRID_SIZE, NUM_CHANNELS, REFERENCE_MASS, subkey, sigma=sigma)\n        pool_states.append(state)\n        pool_formation_ids.append(SEED_ID)  # Mark as seed\n    \n    # Fill remaining slots with formations\n    remaining = pool_size - len(pool_states)\n    for i in range(remaining):\n        key, subkey1, subkey2 = jax.random.split(key, 3)\n        formation_idx = i % num_formations\n        target = targets[formation_names[formation_idx]]\n        \n        if USE_ROTATION_AUGMENTATION:\n            angle = float(jax.random.uniform(subkey1, (), minval=0, maxval=2*jnp.pi))\n            rotated_target = rotate_formation(target, angle)\n        else:\n            rotated_target = target\n        \n        state = create_formation_state(rotated_target, subkey2)\n        pool_states.append(state)\n        pool_formation_ids.append(formation_idx)\n    \n    return jnp.stack(pool_states), jnp.array(pool_formation_ids)\n\n\nkey, pool_key = jax.random.split(key)\ntransition_pool, pool_formation_ids = create_transition_pool(config.pool_size, pool_key)\n\nprint(f\"\\nCreated transition pool: {transition_pool.shape}\")\nprint(f\"\\nPool composition:\")\nfor i, name in enumerate(formation_names):\n    count = int(jnp.sum(pool_formation_ids == i))\n    # Verify mass of first sample of this type\n    sample_idx = int(jnp.where(pool_formation_ids == i)[0][0])\n    sample_mass = float(jnp.sum(transition_pool[sample_idx, ..., 3]))\n    # Mass above background\n    sample_mass_active = float(jnp.sum(jnp.maximum(transition_pool[sample_idx, ..., 3] - BACKGROUND_ALPHA, 0)))\n    print(f\"  {name}: {count} samples, total_mass={sample_mass:.0f}, active_mass={sample_mass_active:.0f}\")\nseed_count = int(jnp.sum(pool_formation_ids == SEED_ID))\nseed_idx = int(jnp.where(pool_formation_ids == SEED_ID)[0][0])\nseed_mass = float(jnp.sum(transition_pool[seed_idx, ..., 3]))\nprint(f\"  gaussian_seed: {seed_count} ({seed_count/config.pool_size:.0%}), mass={seed_mass:.0f}\")\nprint(f\"\\nBackground mass contribution: {GRID_SIZE * GRID_SIZE * BACKGROUND_ALPHA:.0f} per state\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Visualize samples from the transition pool\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\n\nkey, viz_key = jax.random.split(key)\nsample_indices = jax.random.permutation(viz_key, config.pool_size)[:10]\n\n# Extended names for display (includes seed)\ndisplay_names = formation_names + ['seed']\n\nfor i, idx in enumerate(sample_indices):\n    row, col = i // 5, i % 5\n    state = transition_pool[idx]\n    formation_id = int(pool_formation_ids[idx])\n    \n    # Handle seed ID\n    name = display_names[formation_id] if formation_id < len(display_names) else 'seed'\n    \n    axes[row, col].imshow(state[..., 3], cmap='gray', vmin=0, vmax=1)\n    axes[row, col].set_title(f'{name}')\n    axes[row, col].axis('off')\n\nplt.suptitle('Transition Pool Samples (formations + seeds)', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "optimizer = create_optimizer(\n",
    "    learning_rate=config.learning_rate,\n",
    "    gradient_clip=config.gradient_clip\n",
    ")\n",
    "\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=child_nca.apply,\n",
    "    params=params,\n",
    "    tx=optimizer\n",
    ")\n",
    "\n",
    "print(f\"Optimizer ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Training step with GRADIENT ACCUMULATION for stable loss landscape\n",
    "# 1. Fixed num_steps to avoid recompilation\n",
    "# 2. Vectorized checkpoint computation\n",
    "# 3. Alpha-only loss for focused gradient signal\n",
    "# 4. Spatial guidance via target alpha + VELOCITY FLOW FIELD (marching orders!)\n",
    "# 5. Gradient accumulation over multiple micro-batches\n",
    "# 6. SCHEDULED mass conservation (starts low, increases over training)\n",
    "# 7. Intermediate waypoint supervision along trajectory\n",
    "\n",
    "NUM_CHECKPOINTS = 4  # Reduced for faster training\n",
    "\n",
    "# === SCHEDULED MASS CONSERVATION ===\n",
    "MASS_CONSERVATION_WEIGHT_START = 0.05\n",
    "MASS_CONSERVATION_WEIGHT_END = 0.25\n",
    "MASS_CONSERVATION_WARMUP_EPOCHS = 200\n",
    "\n",
    "VIZ_INTERVAL = 100\n",
    "\n",
    "def get_mass_conservation_weight(epoch):\n",
    "    \"\"\"Get scheduled mass conservation weight for current epoch.\"\"\"\n",
    "    if epoch >= MASS_CONSERVATION_WARMUP_EPOCHS:\n",
    "        return MASS_CONSERVATION_WEIGHT_END\n",
    "    progress = epoch / MASS_CONSERVATION_WARMUP_EPOCHS\n",
    "    return MASS_CONSERVATION_WEIGHT_START + progress * (MASS_CONSERVATION_WEIGHT_END - MASS_CONSERVATION_WEIGHT_START)\n",
    "\n",
    "# FIX: Use fixed step count - INCREASED for longer trajectories\n",
    "FIXED_NUM_STEPS = 128  # Reduced for faster iteration\n",
    "\n",
    "# === GRADIENT ACCUMULATION CONFIG ===\n",
    "ACCUM_STEPS = 4\n",
    "\n",
    "# === SIGNAL CHANNELS ===\n",
    "# Now using 6 channels for richer guidance:\n",
    "# [target_alpha, flow_x, flow_y, distance_to_target, target_grad_x, target_grad_y]\n",
    "SIGNAL_CHANNELS = 6\n",
    "MODEL_SIGNAL_CHANNELS = 6  # Full signal to model\n",
    "\n",
    "\n",
    "def compute_distance_field(alpha, threshold=0.1, num_iters=32):\n",
    "    \"\"\"Compute distance field to the nearest cell with alpha > threshold.\n",
    "    \n",
    "    Uses iterative relaxation (JIT-compatible with jax.lax.fori_loop).\n",
    "    Returns distance normalized to [0, 1].\n",
    "    \"\"\"\n",
    "    # Binary mask of \"alive\" cells\n",
    "    alive = (alpha > threshold).astype(jnp.float32)\n",
    "    \n",
    "    h, w = alpha.shape\n",
    "    max_dist = float(h + w)\n",
    "    \n",
    "    # Start with 0 inside, large value outside\n",
    "    dist = jnp.where(alive > 0.5, 0.0, max_dist)\n",
    "    \n",
    "    def relaxation_step(_, dist):\n",
    "        # Pad with large value\n",
    "        padded = jnp.pad(dist, ((1, 1), (1, 1)), mode='constant', constant_values=max_dist)\n",
    "        \n",
    "        # Get minimum of neighbors + 1\n",
    "        neighbors = jnp.stack([\n",
    "            padded[:-2, 1:-1],  # up\n",
    "            padded[2:, 1:-1],   # down\n",
    "            padded[1:-1, :-2],  # left\n",
    "            padded[1:-1, 2:],   # right\n",
    "        ], axis=-1)\n",
    "        min_neighbor = jnp.min(neighbors, axis=-1) + 1\n",
    "        \n",
    "        # Update distance: keep original if alive, else min of current and neighbor+1\n",
    "        return jnp.where(alive > 0.5, 0.0, jnp.minimum(dist, min_neighbor))\n",
    "    \n",
    "    # JIT-compatible loop\n",
    "    dist = jax.lax.fori_loop(0, num_iters, relaxation_step, dist)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    return dist / (max_dist + 1e-6)\n",
    "\n",
    "\n",
    "def compute_flow_field(source_alpha, target_alpha, threshold=0.1):\n",
    "    \"\"\"Compute velocity flow field: direction each cell should move to reach target.\n",
    "    \n",
    "    This gives explicit \"marching orders\" to cells:\n",
    "    - Cells outside target: move toward nearest target cell\n",
    "    - Cells inside target: stay put (small/zero flow)\n",
    "    \n",
    "    Returns:\n",
    "        flow_x: Horizontal velocity component (normalized)\n",
    "        flow_y: Vertical velocity component (normalized)\n",
    "        distance: Distance to target (normalized)\n",
    "    \"\"\"\n",
    "    h, w = target_alpha.shape\n",
    "    \n",
    "    # Compute distance field to target\n",
    "    target_dist = compute_distance_field(target_alpha, threshold)\n",
    "    \n",
    "    # Compute gradient of distance field = flow direction toward target\n",
    "    # Use central differences\n",
    "    # Pad with edge values for boundary handling\n",
    "    dist_padded = jnp.pad(target_dist, ((1, 1), (1, 1)), mode='edge')\n",
    "    \n",
    "    # Gradient (note: negative because we want to move TOWARD low distance)\n",
    "    flow_x = -(dist_padded[1:-1, 2:] - dist_padded[1:-1, :-2]) / 2.0\n",
    "    flow_y = -(dist_padded[2:, 1:-1] - dist_padded[:-2, 1:-1]) / 2.0\n",
    "    \n",
    "    # Normalize flow vectors\n",
    "    flow_mag = jnp.sqrt(flow_x**2 + flow_y**2 + 1e-8)\n",
    "    flow_x = flow_x / (flow_mag + 1e-8)\n",
    "    flow_y = flow_y / (flow_mag + 1e-8)\n",
    "    \n",
    "    # Reduce flow magnitude inside target (cells already at destination)\n",
    "    inside_target = target_alpha > threshold\n",
    "    flow_x = jnp.where(inside_target, flow_x * 0.1, flow_x)\n",
    "    flow_y = jnp.where(inside_target, flow_y * 0.1, flow_y)\n",
    "    \n",
    "    return flow_x, flow_y, target_dist\n",
    "\n",
    "\n",
    "def compute_target_gradients(target_alpha):\n",
    "    \"\"\"Compute Sobel gradients of target alpha for orientation information.\"\"\"\n",
    "    sobel_x = jnp.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=jnp.float32)\n",
    "    sobel_y = sobel_x.T\n",
    "    \n",
    "    target_padded = jnp.pad(target_alpha, ((1, 1), (1, 1)), mode='wrap')\n",
    "    target_4d = target_padded[None, :, :, None]\n",
    "    \n",
    "    grad_x = jax.lax.conv_general_dilated(\n",
    "        target_4d, sobel_x[:, :, None, None], (1, 1), 'VALID',\n",
    "        dimension_numbers=('NHWC', 'HWIO', 'NHWC')\n",
    "    )[0, :, :, 0]\n",
    "    \n",
    "    grad_y = jax.lax.conv_general_dilated(\n",
    "        target_4d, sobel_y[:, :, None, None], (1, 1), 'VALID',\n",
    "        dimension_numbers=('NHWC', 'HWIO', 'NHWC')\n",
    "    )[0, :, :, 0]\n",
    "    \n",
    "    # Normalize\n",
    "    grad_mag = jnp.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
    "    max_mag = jnp.max(grad_mag)\n",
    "    grad_x = grad_x / (max_mag + 1e-8)\n",
    "    grad_y = grad_y / (max_mag + 1e-8)\n",
    "    \n",
    "    return grad_x, grad_y\n",
    "\n",
    "\n",
    "def create_formation_signal_with_flow(batch_size, height, width, target_alpha):\n",
    "    \"\"\"Create goal-conditioning signal with VELOCITY FLOW FIELD.\n",
    "    \n",
    "    Each cell receives 6 channels of guidance:\n",
    "    - Channel 0: Target alpha (what density should I become?)\n",
    "    - Channel 1: Flow X (which direction should I move horizontally?)\n",
    "    - Channel 2: Flow Y (which direction should I move vertically?)\n",
    "    - Channel 3: Distance to target (how far am I from target?)\n",
    "    - Channel 4: Target gradient X (boundary orientation)\n",
    "    - Channel 5: Target gradient Y (boundary orientation)\n",
    "    \n",
    "    The flow field gives explicit \"marching orders\" - telling each cell\n",
    "    WHERE to move, not just what the final state looks like. This is like\n",
    "    giving soldiers actual movement commands during drill.\n",
    "    \"\"\"\n",
    "    # Compute flow field (direction toward target)\n",
    "    flow_x, flow_y, distance = compute_flow_field(\n",
    "        jnp.ones_like(target_alpha) * 0.5,  # Dummy source - flow computed from target\n",
    "        target_alpha\n",
    "    )\n",
    "    \n",
    "    # Compute target gradients (boundary orientation)\n",
    "    grad_x, grad_y = compute_target_gradients(target_alpha)\n",
    "    \n",
    "    # Build signal tensor\n",
    "    signal = jnp.zeros((batch_size, height, width, SIGNAL_CHANNELS))\n",
    "    signal = signal.at[..., 0].set(target_alpha)   # Target density\n",
    "    signal = signal.at[..., 1].set(flow_x)         # Flow direction X\n",
    "    signal = signal.at[..., 2].set(flow_y)         # Flow direction Y\n",
    "    signal = signal.at[..., 3].set(1.0 - distance) # Proximity to target (inverted distance)\n",
    "    signal = signal.at[..., 4].set(grad_x)         # Target gradient X\n",
    "    signal = signal.at[..., 5].set(grad_y)         # Target gradient Y\n",
    "    \n",
    "    return signal\n",
    "\n",
    "\n",
    "def create_interpolated_target(source_alpha, target_alpha, t):\n",
    "    \"\"\"Create an interpolated target between source and target at time t.\n",
    "    \n",
    "    This provides intermediate waypoints for the trajectory, giving the model\n",
    "    a \"trail of breadcrumbs\" to follow rather than just endpoint supervision.\n",
    "    \n",
    "    Args:\n",
    "        source_alpha: Starting formation alpha\n",
    "        target_alpha: Final formation alpha  \n",
    "        t: Interpolation factor [0, 1], where 0=source, 1=target\n",
    "        \n",
    "    Returns:\n",
    "        Interpolated alpha field\n",
    "    \"\"\"\n",
    "    # Simple linear interpolation of alpha values\n",
    "    # This creates intermediate \"ghost\" formations\n",
    "    return (1.0 - t) * source_alpha + t * target_alpha\n",
    "\n",
    "\n",
    "def make_compute_grads_with_waypoints(mass_weight):\n",
    "    \"\"\"Create gradient computation with INTERMEDIATE WAYPOINT SUPERVISION.\n",
    "    \n",
    "    Instead of only supervising the final state, we supervise the trajectory\n",
    "    at multiple intermediate points, creating a smoother loss landscape.\n",
    "    \"\"\"\n",
    "    @jax.jit\n",
    "    def compute_grads(params, batch, target, source_alpha_batch, key, formation_signal, initial_mass):\n",
    "        \"\"\"Compute gradients with waypoint supervision along trajectory.\"\"\"\n",
    "        num_steps = FIXED_NUM_STEPS\n",
    "        \n",
    "        def loss_fn(params):\n",
    "            keys = jax.random.split(key, num_steps)\n",
    "            \n",
    "            checkpoint_interval = num_steps // NUM_CHECKPOINTS\n",
    "            \n",
    "            def step(carry, inputs):\n",
    "                step_idx, subkey = inputs\n",
    "                state_in = carry.at[..., CHILD_CHANNELS.PARENT_SIGNAL_START:CHILD_CHANNELS.PARENT_SIGNAL_END].set(\n",
    "                    formation_signal[..., :2]\n",
    "                )\n",
    "                new_state = child_nca.apply(\n",
    "                    {'params': params}, state_in, subkey, parent_signal=formation_signal[..., :MODEL_SIGNAL_CHANNELS]\n",
    "                )\n",
    "                return new_state, new_state\n",
    "            \n",
    "            step_inputs = (jnp.arange(num_steps), keys)\n",
    "            final, all_states = jax.lax.scan(step, batch, step_inputs)\n",
    "            \n",
    "            # === CHECKPOINT EXTRACTION ===\n",
    "            checkpoint_indices = jnp.array([\n",
    "                (i + 1) * checkpoint_interval - 1 for i in range(NUM_CHECKPOINTS)\n",
    "            ])\n",
    "            checkpoint_indices = jnp.minimum(checkpoint_indices, num_steps - 1)\n",
    "            checkpoint_states = all_states[checkpoint_indices]\n",
    "            \n",
    "            # === WAYPOINT SUPERVISION ===\n",
    "            # Create interpolated targets for each checkpoint\n",
    "            # Checkpoint 0 (early): closer to source\n",
    "            # Checkpoint N (late): closer to target\n",
    "            checkpoint_ts = jnp.array([(i + 1) / NUM_CHECKPOINTS for i in range(NUM_CHECKPOINTS)])\n",
    "            \n",
    "            # Compute loss against interpolated waypoints\n",
    "            checkpoint_losses = []\n",
    "            for i in range(NUM_CHECKPOINTS):\n",
    "                t = checkpoint_ts[i]\n",
    "                \n",
    "                # For later checkpoints, use target directly\n",
    "                # For early checkpoints, use interpolated target\n",
    "                if i >= NUM_CHECKPOINTS - 2:\n",
    "                    # Last 2 checkpoints: match target exactly\n",
    "                    waypoint_target = target[..., 3:4]\n",
    "                else:\n",
    "                    # Earlier checkpoints: interpolated target\n",
    "                    # This gives partial credit for being \"on the way\"\n",
    "                    waypoint_target = target[..., 3:4]  # Still use target but with softer weight\n",
    "                \n",
    "                checkpoint_error = (checkpoint_states[i, ..., 3:4] - waypoint_target) ** 2\n",
    "                checkpoint_losses.append(jnp.mean(checkpoint_error))\n",
    "            \n",
    "            checkpoint_mses = jnp.array(checkpoint_losses)\n",
    "            \n",
    "            # Progressive weighting: early checkpoints matter less\n",
    "            checkpoint_weights = jnp.array([0.05, 0.05, 0.1, 0.1, 0.15, 0.15, 0.2, 0.2])\n",
    "            formation_loss = jnp.sum(checkpoint_weights * checkpoint_mses)\n",
    "            \n",
    "            # === MASS CONSERVATION ===\n",
    "            checkpoint_masses = jnp.sum(checkpoint_states[..., 3], axis=(2, 3))\n",
    "            relative_errors = jnp.abs(checkpoint_masses - initial_mass[None, :]) / (initial_mass[None, :] + 1e-6)\n",
    "            mass_conservation_loss = jnp.mean(relative_errors)\n",
    "            \n",
    "            total_loss = formation_loss + mass_weight * mass_conservation_loss\n",
    "            return total_loss, (final, formation_loss, mass_conservation_loss)\n",
    "        \n",
    "        (loss, (outputs, form_loss, mass_loss)), grads = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
    "        return grads, loss, outputs, form_loss, mass_loss\n",
    "    \n",
    "    return compute_grads\n",
    "\n",
    "\n",
    "# Pre-compile gradient functions for different mass weights\n",
    "MASS_WEIGHT_LEVELS = [0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "compute_grads_funcs = {w: make_compute_grads_with_waypoints(w) for w in MASS_WEIGHT_LEVELS}\n",
    "\n",
    "def get_compute_grads_for_epoch(epoch):\n",
    "    \"\"\"Get the appropriate compute_grads function for current epoch.\"\"\"\n",
    "    weight = get_mass_conservation_weight(epoch)\n",
    "    closest_weight = min(MASS_WEIGHT_LEVELS, key=lambda w: abs(w - weight))\n",
    "    return compute_grads_funcs[closest_weight], closest_weight\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def apply_accumulated_grads(state, accumulated_grads, accum_steps):\n",
    "    \"\"\"Apply accumulated gradients after averaging.\"\"\"\n",
    "    avg_grads = jax.tree_util.tree_map(lambda g: g / accum_steps, accumulated_grads)\n",
    "    avg_grads = normalize_gradients(avg_grads)\n",
    "    state = state.apply_gradients(grads=avg_grads)\n",
    "    return state\n",
    "\n",
    "\n",
    "def accumulate_grads(grads1, grads2):\n",
    "    \"\"\"Add two gradient pytrees together.\"\"\"\n",
    "    return jax.tree_util.tree_map(lambda g1, g2: g1 + g2, grads1, grads2)\n",
    "\n",
    "\n",
    "def zero_grads_like(params):\n",
    "    \"\"\"Create a zero gradient pytree with same structure as params.\"\"\"\n",
    "    return jax.tree_util.tree_map(jnp.zeros_like, params)\n",
    "\n",
    "\n",
    "# === VISUALIZE THE NEW SIGNAL ===\n",
    "print(\"Visualizing VELOCITY FLOW FIELD signal...\")\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for idx, (name, target) in enumerate(targets.items()):\n",
    "    test_signal = create_formation_signal_with_flow(1, GRID_SIZE, GRID_SIZE, target[..., 3])\n",
    "    \n",
    "    # Row 0: Target alpha\n",
    "    axes[0, idx].imshow(test_signal[0, ..., 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, idx].set_title(f'{name}\\n(target)')\n",
    "    axes[0, idx].axis('off')\n",
    "    \n",
    "    # Row 1: Flow field as quiver plot\n",
    "    flow_x = np.array(test_signal[0, ..., 1])\n",
    "    flow_y = np.array(test_signal[0, ..., 2])\n",
    "    \n",
    "    # Subsample for cleaner visualization\n",
    "    step = 4\n",
    "    Y, X = np.mgrid[0:GRID_SIZE:step, 0:GRID_SIZE:step]\n",
    "    U = flow_x[::step, ::step]\n",
    "    V = flow_y[::step, ::step]\n",
    "    \n",
    "    axes[1, idx].imshow(test_signal[0, ..., 0], cmap='gray', vmin=0, vmax=1, alpha=0.3)\n",
    "    axes[1, idx].quiver(X, Y, U, -V, color='red', scale=20, width=0.01)  # -V because imshow flips Y\n",
    "    axes[1, idx].set_title('flow field\\n(marching orders)')\n",
    "    axes[1, idx].axis('off')\n",
    "    \n",
    "    # Row 2: Distance/proximity field\n",
    "    axes[2, idx].imshow(test_signal[0, ..., 3], cmap='hot', vmin=0, vmax=1)\n",
    "    axes[2, idx].set_title('proximity\\n(1=at target)')\n",
    "    axes[2, idx].axis('off')\n",
    "\n",
    "plt.suptitle('Formation Signal with VELOCITY FLOW FIELD\\n(Arrows show \"where to move\")', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"  - Steps per iteration: {FIXED_NUM_STEPS} (increased for longer trajectories)\")\n",
    "print(f\"  - Checkpoints: {NUM_CHECKPOINTS} (more granular supervision)\")\n",
    "print(f\"  - Signal channels: {SIGNAL_CHANNELS}\")\n",
    "print(f\"    [0] Target alpha\")\n",
    "print(f\"    [1] Flow X (horizontal marching direction)\")\n",
    "print(f\"    [2] Flow Y (vertical marching direction)\")\n",
    "print(f\"    [3] Proximity to target (1=at target, 0=far)\")\n",
    "print(f\"    [4] Target gradient X (boundary orientation)\")\n",
    "print(f\"    [5] Target gradient Y (boundary orientation)\")\n",
    "print(f\"  - Mass conservation: {MASS_CONSERVATION_WEIGHT_START} -> {MASS_CONSERVATION_WEIGHT_END}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 Training: Formation Transitions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# === STRATIFIED SAMPLING HELPER ===\n# Ensures each batch has balanced representation from all source formation types\n\ndef get_pool_indices_by_type(pool_ids, num_types):\n    \"\"\"Get indices for each formation type in the pool.\n    \n    Returns:\n        List of arrays, one per formation type (including seeds)\n    \"\"\"\n    indices_by_type = []\n    for type_id in range(num_types):\n        indices = jnp.where(pool_ids == type_id)[0]\n        indices_by_type.append(indices)\n    return indices_by_type\n\n\ndef sample_stratified_batch(key, pool_indices_by_type, batch_size):\n    \"\"\"Sample a batch with balanced representation from available source types.\n    \n    Args:\n        key: PRNG key\n        pool_indices_by_type: List of index arrays, one per type\n        batch_size: Total batch size\n        \n    Returns:\n        Array of pool indices for the batch\n    \"\"\"\n    # Filter to only types that have samples available\n    available_types = [(i, indices) for i, indices in enumerate(pool_indices_by_type) if len(indices) > 0]\n    \n    if len(available_types) == 0:\n        # Fallback: sample randomly from entire pool\n        key, subkey = jax.random.split(key)\n        total_pool_size = sum(len(indices) for indices in pool_indices_by_type)\n        if total_pool_size == 0:\n            raise ValueError(\"Pool is empty!\")\n        all_indices = jnp.concatenate([indices for indices in pool_indices_by_type if len(indices) > 0])\n        return jax.random.choice(subkey, all_indices, shape=(batch_size,), replace=True)\n    \n    num_available_types = len(available_types)\n    samples_per_type = batch_size // num_available_types\n    remainder = batch_size % num_available_types\n    \n    batch_indices = []\n    \n    for idx, (type_id, type_indices) in enumerate(available_types):\n        key, subkey = jax.random.split(key)\n        \n        # Number of samples for this type\n        n_samples = samples_per_type\n        if idx < remainder:\n            n_samples += 1  # Distribute remainder across first few types\n        \n        # Sample from this type's indices\n        if len(type_indices) >= n_samples:\n            perm = jax.random.permutation(subkey, len(type_indices))[:n_samples]\n            selected = type_indices[perm]\n        else:\n            # If not enough samples, sample with replacement\n            selected = jax.random.choice(subkey, type_indices, shape=(n_samples,), replace=True)\n        \n        batch_indices.append(selected)\n    \n    return jnp.concatenate(batch_indices)\n\n\ndef run_trajectory_for_viz(start_state, params, key, target_alpha, num_steps=512):\n    \"\"\"Run a trajectory for visualization (not training).\n    \n    Returns states at regular intervals for animation.\n    Uses the FLOW FIELD signal for guidance.\n    \"\"\"\n    signal = create_formation_signal_with_flow(1, GRID_SIZE, GRID_SIZE, target_alpha)\n    signal_single = signal[0]\n    \n    # Collect frames at regular intervals\n    frame_interval = max(1, num_steps // 100)  # ~100 frames max\n    frames = [np.array(start_state[..., 3])]\n    \n    state_curr = start_state\n    for i in range(num_steps):\n        key, subkey = jax.random.split(key)\n        state_curr = state_curr.at[..., CHILD_CHANNELS.PARENT_SIGNAL_START:CHILD_CHANNELS.PARENT_SIGNAL_END].set(\n            signal_single[..., :2]\n        )\n        state_curr = child_nca.apply(\n            {'params': params}, state_curr, subkey, parent_signal=signal_single[..., :MODEL_SIGNAL_CHANNELS]\n        )\n        \n        if (i + 1) % frame_interval == 0:\n            frames.append(np.array(state_curr[..., 3]))\n    \n    return frames\n\n\ndef create_trajectory_animation(frames, target_alpha, source_name, target_name, epoch):\n    \"\"\"Create and display an animation of the trajectory.\"\"\"\n    from matplotlib.animation import FuncAnimation\n    from IPython.display import HTML, display\n    \n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    # Left: Animation of trajectory\n    im = axes[0].imshow(frames[0], cmap='gray', vmin=0, vmax=1)\n    axes[0].set_title(f'Step 0/{len(frames)-1}')\n    axes[0].axis('off')\n    \n    # Middle: Target formation\n    axes[1].imshow(target_alpha, cmap='gray', vmin=0, vmax=1)\n    axes[1].set_title(f'Target: {target_name}')\n    axes[1].axis('off')\n    \n    # Right: Mass over time\n    masses = [np.sum(f) for f in frames]\n    line, = axes[2].plot([], [], 'b-', linewidth=2)\n    axes[2].axhline(y=np.sum(target_alpha), color='r', linestyle='--', label='Target mass')\n    axes[2].set_xlim(0, len(frames)-1)\n    axes[2].set_ylim(0, max(masses) * 1.2)\n    axes[2].set_xlabel('Frame')\n    axes[2].set_ylabel('Mass')\n    axes[2].set_title('Mass Conservation')\n    axes[2].legend()\n    \n    plt.suptitle(f'Epoch {epoch}: {source_name} → {target_name} ({len(frames)} frames)', fontsize=14)\n    plt.tight_layout()\n    \n    def init():\n        im.set_data(frames[0])\n        line.set_data([], [])\n        return im, line\n    \n    def animate(i):\n        im.set_data(frames[i])\n        axes[0].set_title(f'Frame {i}/{len(frames)-1}')\n        line.set_data(range(i+1), masses[:i+1])\n        return im, line\n    \n    anim = FuncAnimation(fig, animate, init_func=init, frames=len(frames), \n                         interval=50, blit=True)\n    \n    # Display as HTML5 video (works in Jupyter/Colab)\n    try:\n        display(HTML(anim.to_jshtml()))\n    except Exception as e:\n        # Fallback: show first, middle, and last frames\n        print(f\"Animation display failed: {e}\")\n        print(\"Showing key frames instead...\")\n        plt.close(fig)\n        \n        fig2, axes2 = plt.subplots(1, 5, figsize=(15, 3))\n        key_frames = [0, len(frames)//4, len(frames)//2, 3*len(frames)//4, len(frames)-1]\n        for idx, frame_idx in enumerate(key_frames):\n            axes2[idx].imshow(frames[frame_idx], cmap='gray', vmin=0, vmax=1)\n            axes2[idx].set_title(f'Frame {frame_idx}')\n            axes2[idx].axis('off')\n        plt.suptitle(f'Epoch {epoch}: {source_name} → {target_name}', fontsize=14)\n        plt.tight_layout()\n        plt.show()\n    \n    plt.close(fig)\n\n\n# === PERIODIC CHECKPOINTING ===\ndef save_training_checkpoint(checkpoint_path, params, pool, pool_ids, epoch, best_loss, best_params,\n                             losses, form_losses, mass_losses, transition_history):\n    \"\"\"Save a complete training checkpoint for resumption.\"\"\"\n    checkpoint = {\n        'params': params,\n        'best_params': best_params,\n        'pool': np.array(pool),\n        'pool_ids': np.array(pool_ids),\n        'epoch': epoch,\n        'best_loss': best_loss,\n        'config': {\n            'grid_size': GRID_SIZE,\n            'num_channels': NUM_CHANNELS,\n            'hidden_dim': 128,\n            'goal_conditioned': True,\n            'phase': 2,\n            'task': 'transitions',\n            'num_formations': num_formations,\n            'formation_names': formation_names,\n            'signal_channels': SIGNAL_CHANNELS,\n        },\n        'metrics': {\n            'losses': losses,\n            'form_losses': form_losses,\n            'mass_losses': mass_losses,\n            'transition_history': transition_history,\n        }\n    }\n    \n    with open(checkpoint_path, 'wb') as f:\n        pickle.dump(checkpoint, f)\n    \n    print(f\"  [Checkpoint saved: epoch {epoch}, best_loss={best_loss:.6f}]\")\n\n\n# Pre-compute pool indices by type for efficient stratified sampling\nNUM_SOURCE_TYPES = num_formations + 1  # 5 formations + 1 seed type\npool_indices_by_type = get_pool_indices_by_type(pool_formation_ids, NUM_SOURCE_TYPES)\n\nprint(\"=\"*60)\nprint(\"PHASE 2: Formation Transitions with VELOCITY FLOW FIELD\")\nprint(\"=\"*60)\nprint(f\"Task: Start from Formation A (or seed), transition to Formation B\")\nprint(f\"Formations: {formation_names}\")\nprint(f\"Pool: {100*(1-SEED_FRACTION):.0f}% formations, {100*SEED_FRACTION:.0f}% Gaussian seeds\")\nprint(f\"Fixed steps per iteration: {FIXED_NUM_STEPS}\")\nprint(f\"Checkpoints: {NUM_CHECKPOINTS} (more granular supervision)\")\nprint(f\"Gradient accumulation: {ACCUM_STEPS} micro-batches (effective batch size = {config.batch_size * ACCUM_STEPS})\")\nprint(f\"STRATIFIED: Each batch has ~{config.batch_size // NUM_SOURCE_TYPES} samples per source type\")\nprint(f\"Signal: {SIGNAL_CHANNELS}-channel FLOW FIELD (marching orders!)\")\nprint(f\"Visualization: Every {VIZ_INTERVAL} epochs\")\nprint(f\"Checkpointing: Every {config.checkpoint_interval} epochs to {PHASE2_CHECKPOINT}\")\nprint(f\"Mass conservation: SCHEDULED {MASS_CONSERVATION_WEIGHT_START} -> {MASS_CONSERVATION_WEIGHT_END} over {MASS_CONSERVATION_WARMUP_EPOCHS} epochs\")\nprint()\n\nPATIENCE = 200\nMIN_DELTA = 1e-6\nVIZ_INTERVAL = 100  # Visualization with animation\n\n# Initialize or restore training state\nif not RESET and 'loaded_checkpoint' in dir() and loaded_checkpoint is not None:\n    # Restore from checkpoint\n    start_epoch = loaded_checkpoint.get('epoch', 0) + 1\n    losses = loaded_checkpoint['metrics'].get('losses', [])\n    form_losses = loaded_checkpoint['metrics'].get('form_losses', [])\n    mass_losses = loaded_checkpoint['metrics'].get('mass_losses', [])\n    transition_history = loaded_checkpoint['metrics'].get('transition_history', [])\n    best_loss = loaded_checkpoint.get('best_loss', float('inf'))\n    best_params = loaded_checkpoint.get('best_params', state.params)\n    \n    # Restore pool if available\n    if 'pool' in loaded_checkpoint:\n        current_pool = jnp.array(loaded_checkpoint['pool'])\n        current_pool_ids = jnp.array(loaded_checkpoint['pool_ids'])\n        print(f\"Restored pool from checkpoint (shape: {current_pool.shape})\")\n    else:\n        current_pool = transition_pool.copy()\n        current_pool_ids = pool_formation_ids.copy()\n        print(\"Pool not in checkpoint, using fresh pool\")\n    \n    epochs_without_improvement = 0\n    print(f\"Resuming training from epoch {start_epoch}\")\n    print(f\"  Previous best loss: {best_loss:.6f}\")\n    print(f\"  Metrics restored: {len(losses)} loss values\")\nelse:\n    start_epoch = 0\n    losses = []\n    form_losses = []\n    mass_losses = []\n    transition_history = []\n    best_loss = float('inf')\n    best_params = state.params\n    epochs_without_improvement = 0\n    current_pool = transition_pool.copy()\n    current_pool_ids = pool_formation_ids.copy()\n    print(\"Starting fresh training from epoch 0\")\n\ntimes = []\n\n# Track pool indices by type (will update as pool evolves)\ncurrent_pool_indices_by_type = get_pool_indices_by_type(current_pool_ids, NUM_SOURCE_TYPES)\n\n# Extended formation names to include seed\nextended_names = formation_names + ['seed']\n\nprint(\"Compiling JIT (first epoch will be slow)...\")\n\nfor epoch in range(start_epoch, PHASE2_EPOCHS):\n    start_time = time.time()\n    key, epoch_key = jax.random.split(key)\n    \n    # Pick a TARGET formation for this epoch (same target for all micro-batches)\n    epoch_key, target_key, angle_key = jax.random.split(epoch_key, 3)\n    target_idx = int(jax.random.randint(target_key, (), 0, num_formations))\n    target = targets[formation_names[target_idx]]\n    \n    # Rotation augmentation for target\n    if USE_ROTATION_AUGMENTATION:\n        if ROTATION_CONTINUOUS:\n            angle = float(jax.random.uniform(angle_key, (), minval=0, maxval=2 * jnp.pi))\n        else:\n            angle = float(jax.random.randint(angle_key, (), 0, 4)) * (jnp.pi / 2)\n        target = rotate_formation(target, angle)\n    else:\n        angle = 0.0\n\n    # === SCHEDULED MASS CONSERVATION ===\n    compute_grads_fn, current_mass_weight = get_compute_grads_for_epoch(epoch)\n    \n    # === GRADIENT ACCUMULATION with STRATIFIED SAMPLING ===\n    accumulated_grads = zero_grads_like(state.params)\n    total_loss = 0.0\n    total_form_loss = 0.0\n    total_mass_loss = 0.0\n    all_outputs = []\n    all_indices = []\n    all_source_formations = []\n    batch_mass_before_sum = 0.0\n    batch_mass_after_sum = 0.0\n    \n    for accum_idx in range(ACCUM_STEPS):\n        epoch_key, sample_key, step_key = jax.random.split(epoch_key, 3)\n        \n        # === STRATIFIED SAMPLING ===\n        batch_indices = sample_stratified_batch(\n            sample_key, current_pool_indices_by_type, config.batch_size\n        )\n        \n        batch = current_pool[batch_indices]\n        batch_source_formations = current_pool_ids[batch_indices]\n        \n        # Compute initial mass for mass conservation\n        initial_mass = jnp.sum(batch[..., 3], axis=(1, 2))\n        batch_mass_before_sum += float(jnp.mean(initial_mass))\n        \n        # Create FLOW FIELD signal (6 channels with marching orders)\n        formation_signal = create_formation_signal_with_flow(\n            config.batch_size, GRID_SIZE, GRID_SIZE, target[..., 3]\n        )\n        \n        # Source alpha for waypoint supervision\n        source_alpha_batch = batch[..., 3:4]\n        \n        # Compute gradients for this micro-batch\n        grads, loss, outputs, form_loss, mass_loss = compute_grads_fn(\n            state.params, batch, target, source_alpha_batch, step_key, formation_signal, initial_mass\n        )\n        \n        # Accumulate gradients\n        accumulated_grads = accumulate_grads(accumulated_grads, grads)\n        \n        # Track losses\n        total_loss += float(loss)\n        total_form_loss += float(form_loss)\n        total_mass_loss += float(mass_loss)\n        \n        # Track outputs for pool update\n        all_outputs.append(outputs)\n        all_indices.append(batch_indices)\n        all_source_formations.append(batch_source_formations)\n        batch_mass_after_sum += float(jnp.mean(jnp.sum(outputs[..., 3], axis=(1, 2))))\n    \n    # Average the metrics\n    avg_loss = total_loss / ACCUM_STEPS\n    avg_form_loss = total_form_loss / ACCUM_STEPS\n    avg_mass_loss = total_mass_loss / ACCUM_STEPS\n    avg_mass_before = batch_mass_before_sum / ACCUM_STEPS\n    avg_mass_after = batch_mass_after_sum / ACCUM_STEPS\n    mass_retention = avg_mass_after / (avg_mass_before + 1e-6)\n    \n    # Apply accumulated gradients\n    state = apply_accumulated_grads(state, accumulated_grads, ACCUM_STEPS)\n    \n    # === PERIODIC CHECKPOINT ===\n    if epoch > 0 and epoch % config.checkpoint_interval == 0:\n        save_training_checkpoint(\n            PHASE2_CHECKPOINT, state.params, current_pool, current_pool_ids,\n            epoch, best_loss, best_params, losses, form_losses, mass_losses, transition_history\n        )\n    \n    # === VISUALIZATION ===\n    if epoch % VIZ_INTERVAL == 0 and epoch > 0:\n        print(f\"\\n{'='*60}\")\n        print(f\"Visualization at Epoch {epoch}\")\n        print(f\"{'='*60}\")\n        \n        fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n        \n        start_alpha = np.array(all_outputs[0][0, ..., 3])\n        source_id = int(all_source_formations[0][0])\n        source_name = extended_names[source_id] if source_id < len(extended_names) else 'seed'\n        axes[0].imshow(start_alpha, cmap='gray', vmin=0, vmax=1)\n        axes[0].set_title(f'Output sample\\n(mass: {np.sum(start_alpha):.0f})')\n        axes[0].axis('off')\n        \n        axes[1].imshow(np.array(target[..., 3]), cmap='gray', vmin=0, vmax=1)\n        axes[1].set_title(f'Target: {formation_names[target_idx]}\\n(angle: {np.degrees(angle):.0f}°)')\n        axes[1].axis('off')\n        \n        pool_masses = [float(jnp.sum(current_pool[i, ..., 3])) for i in range(min(64, config.pool_size))]\n        axes[2].hist(pool_masses, bins=20, color='steelblue', edgecolor='black')\n        axes[2].set_xlabel('Mass')\n        axes[2].set_title('Pool Health')\n        \n        plt.suptitle(f'Epoch {epoch} | Best Loss: {best_loss:.6f}')\n        plt.tight_layout()\n        plt.show()\n        \n        # Trajectory animation\n        key, viz_key, state_key = jax.random.split(key, 3)\n        viz_source_idx = int(jax.random.randint(viz_key, (), 0, num_formations))\n        viz_source_name = formation_names[viz_source_idx]\n        viz_target_name = formation_names[target_idx]\n        viz_start_state = create_formation_state(targets[viz_source_name], state_key)\n        \n        print(f\"\\nGenerating trajectory animation: {viz_source_name} → {viz_target_name}...\")\n        \n        key, traj_key = jax.random.split(key)\n        frames = run_trajectory_for_viz(viz_start_state, state.params, traj_key, target[..., 3], num_steps=512)\n        create_trajectory_animation(frames, np.array(target[..., 3]), viz_source_name, viz_target_name, epoch)\n        \n        print(f\"{'='*60}\\n\")\n    \n    # Check for NaN/Inf\n    if np.isnan(avg_loss) or np.isinf(avg_loss):\n        print(f\"\\nEarly stopping at epoch {epoch}: loss is {avg_loss}\")\n        state = state.replace(params=best_params)\n        break\n    \n    # Track best model\n    if avg_loss < best_loss - MIN_DELTA:\n        best_loss = avg_loss\n        best_params = state.params\n        epochs_without_improvement = 0\n    else:\n        epochs_without_improvement += 1\n    \n    if epochs_without_improvement >= PATIENCE:\n        print(f\"\\nEarly stopping at epoch {epoch}: no improvement for {PATIENCE} epochs\")\n        state = state.replace(params=best_params)\n        break\n    \n    # Pool update\n    for outputs, batch_indices, batch_source_formations in zip(all_outputs, all_indices, all_source_formations):\n        current_pool = current_pool.at[batch_indices].set(outputs)\n        current_pool_ids = current_pool_ids.at[batch_indices].set(target_idx)\n    \n    current_pool_indices_by_type = get_pool_indices_by_type(current_pool_ids, NUM_SOURCE_TYPES)\n    \n    elapsed = time.time() - start_time\n    losses.append(avg_loss)\n    form_losses.append(avg_form_loss)\n    mass_losses.append(avg_mass_loss)\n    times.append(elapsed)\n    \n    # Track transition history\n    source_counts = {}\n    for src_formations in all_source_formations:\n        for src_id in np.array(src_formations):\n            src_name = extended_names[src_id] if src_id < len(extended_names) else 'seed'\n            source_counts[src_name] = source_counts.get(src_name, 0) + 1\n    \n    source_formation = int(all_source_formations[0][0])\n    transition_history.append((source_formation, target_idx))\n    \n    if epoch % config.log_interval == 0:\n        src_summary = \", \".join([f\"{k}:{v}\" for k, v in sorted(source_counts.items())])\n        tgt = formation_names[target_idx]\n        print(f\"Epoch {epoch:4d}: loss={avg_loss:.6f} (form:{avg_form_loss:.6f}, mass:{avg_mass_loss:.4f}), \" +\n              f\"retention={mass_retention:.1%}, mass_w={current_mass_weight:.2f}, -> {tgt}\")\n        print(f\"         sources: [{src_summary}]\")\n\n# Save final checkpoint\nsave_training_checkpoint(\n    PHASE2_CHECKPOINT, state.params, current_pool, current_pool_ids,\n    epoch, best_loss, best_params, losses, form_losses, mass_losses, transition_history\n)\n\nprint(f\"\\nPhase 2 complete. Best loss: {best_loss:.6f}\")\nif len(times) > 1:\n    print(f\"Average time per epoch (after JIT): {np.mean(times[1:]):.3f}s\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nwindow = 100\n\n# Total loss\naxes[0, 0].plot(losses, alpha=0.3)\nif len(losses) > window:\n    smoothed = np.convolve(losses, np.ones(window)/window, mode='valid')\n    axes[0, 0].plot(range(window-1, len(losses)), smoothed, 'r-', linewidth=2)\naxes[0, 0].set_xlabel('Epoch')\naxes[0, 0].set_ylabel('Total Loss')\naxes[0, 0].set_title('Total Loss')\naxes[0, 0].set_yscale('log')\n\n# Formation loss\naxes[0, 1].plot(form_losses, alpha=0.3, color='blue')\nif len(form_losses) > window:\n    smoothed = np.convolve(form_losses, np.ones(window)/window, mode='valid')\n    axes[0, 1].plot(range(window-1, len(form_losses)), smoothed, 'b-', linewidth=2)\naxes[0, 1].set_xlabel('Epoch')\naxes[0, 1].set_ylabel('Formation Loss')\naxes[0, 1].set_title('Formation Loss (alpha-only)')\naxes[0, 1].set_yscale('log')\n\n# Mass conservation\naxes[1, 0].plot(mass_losses, alpha=0.3, color='green')\nif len(mass_losses) > window:\n    smoothed = np.convolve(mass_losses, np.ones(window)/window, mode='valid')\n    axes[1, 0].plot(range(window-1, len(mass_losses)), smoothed, 'g-', linewidth=2)\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('Mass Conservation Error')\naxes[1, 0].set_title('Mass Conservation Loss')\n\n# Transition matrix (includes seed as source)\nextended_names = formation_names + ['seed']\nnum_extended = len(extended_names)\ntransition_counts = np.zeros((num_extended, num_formations))  # Source can be seed, target is always formation\nfor src, tgt in transition_history:\n    if src < num_extended and tgt < num_formations:\n        transition_counts[src, tgt] += 1\n\nim = axes[1, 1].imshow(transition_counts, cmap='Blues', aspect='auto')\naxes[1, 1].set_xticks(range(num_formations))\naxes[1, 1].set_yticks(range(num_extended))\naxes[1, 1].set_xticklabels(formation_names, rotation=45, ha='right')\naxes[1, 1].set_yticklabels(extended_names)\naxes[1, 1].set_xlabel('Target')\naxes[1, 1].set_ylabel('Source')\naxes[1, 1].set_title('Transition Counts (includes seed->formation)')\nplt.colorbar(im, ax=axes[1, 1])\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "checkpoint = {\n",
    "    'params': state.params,\n",
    "    'config': {\n",
    "        'grid_size': GRID_SIZE,\n",
    "        'num_channels': NUM_CHANNELS,\n",
    "        'hidden_dim': 128,\n",
    "        'goal_conditioned': True,\n",
    "        'phase': 2,\n",
    "        'task': 'transitions',\n",
    "        'num_formations': num_formations,\n",
    "        'formation_names': formation_names,\n",
    "    },\n",
    "    'metrics': {\n",
    "        'losses': losses,\n",
    "        'form_losses': form_losses,\n",
    "        'mass_losses': mass_losses,\n",
    "        'best_loss': best_loss,\n",
    "        'transition_history': transition_history,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(PHASE2_CHECKPOINT, 'wb') as f:\n",
    "    pickle.dump(checkpoint, f)\n",
    "\n",
    "print(f\"Checkpoint saved to {PHASE2_CHECKPOINT}\")\n",
    "print(f\"Best loss: {best_loss:.6f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Evaluation: Formation Transitions\n",
    "\n",
    "Test that the model can transition between any pair of formations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def run_transition(start_state, params, key, target_alpha, num_steps=150):\n    \"\"\"Run a formation transition using target alpha + gradients as spatial guidance.\n    \n    Args:\n        start_state: Starting formation state\n        params: Model parameters\n        key: PRNG key\n        target_alpha: Target formation's alpha channel (H, W) for spatial guidance\n        num_steps: Number of NCA steps\n    \n    Returns:\n        List of states (trajectory)\n    \"\"\"\n    # Create 4-channel signal with alpha + gradients\n    signal = create_formation_signal_spatial(1, GRID_SIZE, GRID_SIZE, target_alpha)\n    signal_single = signal[0]\n    \n    trajectory = [start_state]\n    state_curr = start_state\n    \n    for i in range(num_steps):\n        key, subkey = jax.random.split(key)\n        # Write first 2 channels to state's parent signal slots\n        state_curr = state_curr.at[..., CHILD_CHANNELS.PARENT_SIGNAL_START:CHILD_CHANNELS.PARENT_SIGNAL_END].set(\n            signal_single[..., :2]\n        )\n        # Pass FULL 4-channel signal to model\n        state_curr = child_nca.apply(\n            {'params': params}, state_curr, subkey, parent_signal=signal_single[..., :MODEL_SIGNAL_CHANNELS]\n        )\n        trajectory.append(state_curr)\n    \n    return trajectory\n\nprint(\"Transition function ready (using FULL 4-channel spatial guidance).\")\nprint(f\"  Signal channels: {SIGNAL_CHANNELS} (alpha, grad_x, grad_y, reserved)\")\nprint(f\"  Model signal channels: {MODEL_SIGNAL_CHANNELS}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Test all pairwise transitions (5x5 = 25 pairs) + seed->formation (5 more)\nprint(\"Testing all formation transitions...\")\n\ntransition_mses = np.zeros((num_formations, num_formations))\ntransition_retentions = np.zeros((num_formations, num_formations))\n\n# Also test seed -> formation\nseed_mses = np.zeros(num_formations)\nseed_retentions = np.zeros(num_formations)\n\nkey, eval_key = jax.random.split(key)\n\n# Formation -> Formation transitions\nfor src_idx, src_name in enumerate(formation_names):\n    # Create starting state from source formation\n    eval_key, state_key = jax.random.split(eval_key)\n    start_state = create_formation_state(targets[src_name], state_key)\n    initial_mass = float(jnp.sum(start_state[..., 3]))\n    \n    for tgt_idx, tgt_name in enumerate(formation_names):\n        eval_key, run_key = jax.random.split(eval_key)\n        \n        target = targets[tgt_name]\n        \n        # Run transition with target alpha as spatial guidance\n        trajectory = run_transition(start_state, state.params, run_key, target[..., 3], num_steps=150)\n        final = trajectory[-1]\n        \n        # Compute metrics using ALPHA-ONLY MSE\n        mse = float(np.mean((np.array(target[..., 3]) - np.array(final[..., 3]))**2))\n        final_mass = float(jnp.sum(final[..., 3]))\n        retention = final_mass / initial_mass\n        \n        transition_mses[src_idx, tgt_idx] = mse\n        transition_retentions[src_idx, tgt_idx] = retention\n\n# Seed -> Formation transitions\nprint(\"Testing seed -> formation transitions...\")\nfor tgt_idx, tgt_name in enumerate(formation_names):\n    eval_key, seed_key, run_key = jax.random.split(eval_key, 3)\n    \n    # Create Gaussian seed\n    seed_state = create_gaussian_seed(GRID_SIZE, GRID_SIZE, NUM_CHANNELS, REFERENCE_MASS, seed_key, sigma=10.0)\n    initial_mass = float(jnp.sum(seed_state[..., 3]))\n    \n    target = targets[tgt_name]\n    \n    # Run transition\n    trajectory = run_transition(seed_state, state.params, run_key, target[..., 3], num_steps=150)\n    final = trajectory[-1]\n    \n    # Compute metrics\n    mse = float(np.mean((np.array(target[..., 3]) - np.array(final[..., 3]))**2))\n    final_mass = float(jnp.sum(final[..., 3]))\n    retention = final_mass / initial_mass\n    \n    seed_mses[tgt_idx] = mse\n    seed_retentions[tgt_idx] = retention\n\nprint(\"Done!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize transition matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# MSE matrix\n",
    "im1 = axes[0].imshow(transition_mses, cmap='Reds', vmin=0)\n",
    "axes[0].set_xticks(range(num_formations))\n",
    "axes[0].set_yticks(range(num_formations))\n",
    "axes[0].set_xticklabels(formation_names, rotation=45, ha='right')\n",
    "axes[0].set_yticklabels(formation_names)\n",
    "axes[0].set_xlabel('Target Formation')\n",
    "axes[0].set_ylabel('Source Formation')\n",
    "axes[0].set_title('Transition MSE (lower is better)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(num_formations):\n",
    "    for j in range(num_formations):\n",
    "        axes[0].text(j, i, f'{transition_mses[i,j]:.3f}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "# Retention matrix\n",
    "im2 = axes[1].imshow(transition_retentions, cmap='Greens', vmin=0.5, vmax=1.5)\n",
    "axes[1].set_xticks(range(num_formations))\n",
    "axes[1].set_yticks(range(num_formations))\n",
    "axes[1].set_xticklabels(formation_names, rotation=45, ha='right')\n",
    "axes[1].set_yticklabels(formation_names)\n",
    "axes[1].set_xlabel('Target Formation')\n",
    "axes[1].set_ylabel('Source Formation')\n",
    "axes[1].set_title('Mass Retention (1.0 = perfect)')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "for i in range(num_formations):\n",
    "    for j in range(num_formations):\n",
    "        axes[1].text(j, i, f'{transition_retentions[i,j]:.2f}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Visualize specific transitions\ntest_transitions = [\n    ('line', 'wedge'),\n    ('wedge', 'square'),\n    ('square', 'column'),\n    ('column', 'phalanx'),\n]\n\nfig, axes = plt.subplots(len(test_transitions), 6, figsize=(18, 3*len(test_transitions)))\n\ntimesteps = [0, 30, 60, 90, 120, 150]\n\nfor row, (src_name, tgt_name) in enumerate(test_transitions):\n    src_idx = formation_names.index(src_name)\n    tgt_idx = formation_names.index(tgt_name)\n    \n    eval_key, state_key, run_key = jax.random.split(eval_key, 3)\n    start_state = create_formation_state(targets[src_name], state_key)\n    target = targets[tgt_name]\n    \n    # Use target alpha as spatial guidance\n    trajectory = run_transition(start_state, state.params, run_key, target[..., 3], num_steps=150)\n    \n    for col, t in enumerate(timesteps):\n        if t < len(trajectory):\n            axes[row, col].imshow(trajectory[t][..., 3], cmap='gray', vmin=0, vmax=1)\n        axes[row, col].set_title(f't={t}')\n        axes[row, col].axis('off')\n    \n    axes[row, 0].set_ylabel(f'{src_name} -> {tgt_name}', fontsize=10)\n\nplt.suptitle('Formation Transitions Over Time', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Test rotation during transition\nprint(\"Testing line -> wedge with different target rotations...\")\n\nangles_test = [0, np.pi/4, np.pi/2, np.pi]\nangle_labels = ['0°', '45°', '90°', '180°']\n\nfig, axes = plt.subplots(2, len(angles_test), figsize=(3*len(angles_test), 6))\n\neval_key, state_key = jax.random.split(eval_key)\nstart_state = create_formation_state(targets['line'], state_key)\n\nfor col, (angle, label) in enumerate(zip(angles_test, angle_labels)):\n    eval_key, run_key = jax.random.split(eval_key)\n    \n    # Target wedge at this angle\n    rotated_target = rotate_formation(targets['wedge'], float(angle))\n    \n    # Use rotated target's alpha as spatial guidance\n    trajectory = run_transition(start_state, state.params, run_key, rotated_target[..., 3], num_steps=150)\n    final = trajectory[-1]\n    \n    # Target\n    axes[0, col].imshow(rotated_target[..., 3], cmap='gray', vmin=0, vmax=1)\n    axes[0, col].set_title(f'Target @ {label}')\n    axes[0, col].axis('off')\n    \n    # Result - use alpha-only MSE\n    mse = np.mean((np.array(rotated_target[..., 3]) - np.array(final[..., 3]))**2)\n    axes[1, col].imshow(final[..., 3], cmap='gray', vmin=0, vmax=1)\n    axes[1, col].set_title(f'Result (MSE: {mse:.4f})')\n    axes[1, col].axis('off')\n\nplt.suptitle('Line -> Wedge with Rotation', fontsize=14)\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria Check"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(\"=\" * 60)\nprint(\"PHASE 2 SUCCESS CRITERIA: Formation Transitions\")\nprint(\"=\" * 60)\nprint(\"(Using alpha-only MSE for shape matching)\")\n\n# Analyze transition matrix (formation -> formation)\navg_mse = np.mean(transition_mses)\nmax_mse = np.max(transition_mses)\navg_retention = np.mean(transition_retentions)\nmin_retention = np.min(transition_retentions)\n\n# Off-diagonal (actual transitions, not same-to-same)\noff_diag_mask = ~np.eye(num_formations, dtype=bool)\navg_transition_mse = np.mean(transition_mses[off_diag_mask])\navg_transition_retention = np.mean(transition_retentions[off_diag_mask])\n\n# Seed -> formation metrics\navg_seed_mse = np.mean(seed_mses)\nmax_seed_mse = np.max(seed_mses)\navg_seed_retention = np.mean(seed_retentions)\nmin_seed_retention = np.min(seed_retentions)\n\nprint(\"\\n=== Formation -> Formation Metrics (alpha-only) ===\")\nprint(f\"  Average MSE (all pairs): {avg_mse:.6f}\")\nprint(f\"  Average MSE (transitions only): {avg_transition_mse:.6f}\")\nprint(f\"  Worst MSE: {max_mse:.6f}\")\nprint(f\"  Average retention: {avg_retention:.1%}\")\nprint(f\"  Worst retention: {min_retention:.1%}\")\n\nprint(\"\\n=== Seed -> Formation Metrics (alpha-only) ===\")\nprint(f\"  Average MSE: {avg_seed_mse:.6f}\")\nprint(f\"  Worst MSE: {max_seed_mse:.6f}\")\nprint(f\"  Average retention: {avg_seed_retention:.1%}\")\nprint(f\"  Worst retention: {min_seed_retention:.1%}\")\n\nprint(\"\\nPer-Transition Analysis (Formation -> Formation):\")\nfor src_idx, src_name in enumerate(formation_names):\n    for tgt_idx, tgt_name in enumerate(formation_names):\n        if src_idx != tgt_idx:\n            mse = transition_mses[src_idx, tgt_idx]\n            ret = transition_retentions[src_idx, tgt_idx]\n            status = \"OK\" if mse < 0.02 and ret > 0.85 else \"NEEDS WORK\"\n            print(f\"  {src_name:8s} -> {tgt_name:8s}: MSE={mse:.4f}, Retention={ret:.1%} [{status}]\")\n\nprint(\"\\nPer-Transition Analysis (Seed -> Formation):\")\nfor tgt_idx, tgt_name in enumerate(formation_names):\n    mse = seed_mses[tgt_idx]\n    ret = seed_retentions[tgt_idx]\n    status = \"OK\" if mse < 0.02 and ret > 0.85 else \"NEEDS WORK\"\n    print(f\"  seed     -> {tgt_name:8s}: MSE={mse:.4f}, Retention={ret:.1%} [{status}]\")\n\n# Success criteria\nprint(\"\\n\" + \"=\" * 60)\ncriteria = [\n    (\"Avg formation->formation MSE < 0.02\", avg_transition_mse, 0.02, avg_transition_mse < 0.02),\n    (\"Worst formation->formation MSE < 0.05\", max_mse, 0.05, max_mse < 0.05),\n    (\"Avg seed->formation MSE < 0.02\", avg_seed_mse, 0.02, avg_seed_mse < 0.02),\n    (\"Worst seed->formation MSE < 0.05\", max_seed_mse, 0.05, max_seed_mse < 0.05),\n    (\"Avg retention > 85%\", min(avg_transition_retention, avg_seed_retention), 0.85, \n     avg_transition_retention > 0.85 and avg_seed_retention > 0.85),\n    (\"Worst retention > 70%\", min(min_retention, min_seed_retention), 0.70, \n     min_retention > 0.70 and min_seed_retention > 0.70),\n]\n\nall_passed = True\nfor name, value, threshold, passed in criteria:\n    status = \"PASS\" if passed else \"FAIL\"\n    print(f\"{name}: {value:.4f} (threshold: {threshold}) [{status}]\")\n    if not passed:\n        all_passed = False\n\nprint(\"=\" * 60)\nif all_passed:\n    print(\"ALL CRITERIA PASSED - Ready for Phase 3!\")\n    print(\"\\nNext: Implement combat dynamics with adversarial armies\")\nelse:\n    print(\"SOME CRITERIA FAILED - Consider more training\")\n    print(\"\\nTry: Set RESET=False and run training again\")",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
