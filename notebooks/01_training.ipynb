{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Setup: Pull latest code and install package\n",
    "# Run this cell first to ensure you have the latest version\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "REPO_URL = \"https://github.com/JackHopkins/FormationHNCA.git\"\n",
    "REPO_DIR = \"/workspace/FormationHNCA\"  # Colab/remote path\n",
    "\n",
    "# Clone or pull latest\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(\"Pulling latest changes...\")\n",
    "    os.chdir(REPO_DIR)\n",
    "    subprocess.run([\"git\", \"pull\"], check=True)\n",
    "else:\n",
    "    print(\"Cloning repository...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, REPO_DIR], check=True)\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "# Install package\n",
    "print(\"Installing package...\")\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"-e\", \".\"], check=True)\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"Setup complete!\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Core imports\nimport sys\nsys.path.insert(0, 'src')\n\nimport jax\nimport jax.numpy as jnp\nfrom flax import linen as nn\nfrom flax.training import train_state\nimport optax\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom functools import partial\nimport time\n\n# Battle NCA imports\nfrom battle_nca.core import NCA, perceive\nfrom battle_nca.core.nca import create_seed\nfrom battle_nca.hierarchy import ChildNCA, ParentNCA, HierarchicalNCA\nfrom battle_nca.hierarchy.child_nca import create_army_seed, CHILD_CHANNELS\nfrom battle_nca.combat import FormationTargets, create_formation_target\nfrom battle_nca.combat.formations import FormationTypes\nfrom battle_nca.combat.losses import formation_loss, total_battle_loss\nfrom battle_nca.training import NCAPool, Trainer, TrainingConfig\nfrom battle_nca.training.optimizers import create_optimizer, normalize_gradients\nfrom battle_nca.utils.visualization import render_state, plot_training_curves\n\nprint(f\"JAX devices: {jax.devices()}\")\nprint(f\"JAX version: {jax.__version__}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Core imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "# Battle NCA imports\n",
    "from battle_nca.core import NCA, perceive\n",
    "from battle_nca.core.nca import create_seed\n",
    "from battle_nca.hierarchy import ChildNCA, ParentNCA, HierarchicalNCA\n",
    "from battle_nca.hierarchy.child_nca import create_army_seed, CHILD_CHANNELS\n",
    "from battle_nca.combat import FormationTargets, create_formation_target\n",
    "from battle_nca.combat.formations import FormationTypes\n",
    "from battle_nca.combat.losses import formation_loss, total_battle_loss\n",
    "from battle_nca.training import NCAPool, Trainer, TrainingConfig\n",
    "from battle_nca.training.optimizers import create_optimizer, normalize_gradients\n",
    "from battle_nca.utils.visualization import render_state, plot_training_curves\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print(f\"JAX version: {jax.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid configuration\n",
    "GRID_SIZE = 64  # 64x64 grid (can scale to 200x200 for full simulation)\n",
    "NUM_CHANNELS = 24  # Full battle state channels\n",
    "\n",
    "# Training configuration\n",
    "config = TrainingConfig(\n",
    "    batch_size=32,\n",
    "    pool_size=1024,\n",
    "    min_steps=64,\n",
    "    max_steps=96,\n",
    "    learning_rate=2e-3,\n",
    "    gradient_clip=1.0,\n",
    "    damage_samples=3,\n",
    "    damage_start_epoch=500,\n",
    "    log_interval=100,\n",
    "    checkpoint_interval=500\n",
    ")\n",
    "\n",
    "# Phase epochs\n",
    "PHASE1_EPOCHS = 1500\n",
    "PHASE2_EPOCHS = 2500\n",
    "PHASE3_EPOCHS = 4000\n",
    "\n",
    "# Random seed\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create child NCA model\n",
    "child_nca = ChildNCA(\n",
    "    num_channels=NUM_CHANNELS,\n",
    "    hidden_dim=128,\n",
    "    fire_rate=0.5,\n",
    "    use_circular_padding=True\n",
    ")\n",
    "\n",
    "# Create seed state\n",
    "seed = create_army_seed(\n",
    "    height=GRID_SIZE,\n",
    "    width=GRID_SIZE,\n",
    "    team_color=(1.0, 0.0, 0.0),  # Red team\n",
    "    unit_type=0,\n",
    "    formation_id=0,\n",
    "    spawn_region=(GRID_SIZE//2 - 2, GRID_SIZE//2 + 2, GRID_SIZE//2 - 2, GRID_SIZE//2 + 2)\n",
    ")\n",
    "\n",
    "print(f\"Seed shape: {seed.shape}\")\n",
    "print(f\"Seed active cells: {jnp.sum(seed[..., 3] > 0.5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "key = jax.random.PRNGKey(SEED)\n",
    "key, init_key = jax.random.split(key)\n",
    "\n",
    "variables = child_nca.init(init_key, seed, jax.random.PRNGKey(0))\n",
    "params = variables['params']\n",
    "\n",
    "# Count parameters\n",
    "def count_params(params):\n",
    "    return sum(p.size for p in jax.tree_util.tree_leaves(params))\n",
    "\n",
    "print(f\"Total parameters: {count_params(params):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize seed\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# RGBA\n",
    "axes[0].imshow(np.clip(seed[..., :4], 0, 1))\n",
    "axes[0].set_title('Seed RGBA')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Alpha channel\n",
    "axes[1].imshow(seed[..., 3], cmap='gray', vmin=0, vmax=1)\n",
    "axes[1].set_title('Seed Alpha')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Hidden channels (mean)\n",
    "axes[2].imshow(seed[..., 15:].mean(axis=-1), cmap='viridis')\n",
    "axes[2].set_title('Seed Hidden (mean)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Target Formations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all formation targets\n",
    "targets = {\n",
    "    'line': FormationTargets.line(GRID_SIZE, GRID_SIZE),\n",
    "    'phalanx': FormationTargets.phalanx(GRID_SIZE, GRID_SIZE, depth=8),\n",
    "    'square': FormationTargets.square(GRID_SIZE, GRID_SIZE, thickness=3),\n",
    "    'wedge': FormationTargets.wedge(GRID_SIZE, GRID_SIZE),\n",
    "    'column': FormationTargets.column(GRID_SIZE, GRID_SIZE, col_width=4),\n",
    "}\n",
    "\n",
    "# Visualize targets\n",
    "fig, axes = plt.subplots(1, len(targets), figsize=(15, 3))\n",
    "\n",
    "for ax, (name, target) in zip(axes, targets.items()):\n",
    "    ax.imshow(target[..., 3], cmap='gray', vmin=0, vmax=1)\n",
    "    ax.set_title(name.capitalize())\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Static Formation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = create_optimizer(\n",
    "    learning_rate=config.learning_rate,\n",
    "    gradient_clip=config.gradient_clip\n",
    ")\n",
    "\n",
    "# Create training state\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=child_nca.apply,\n",
    "    params=params,\n",
    "    tx=optimizer\n",
    ")\n",
    "\n",
    "# Create pool\n",
    "pool = NCAPool(seed, config.pool_size)\n",
    "\n",
    "# Target formation for Phase 1\n",
    "target = targets['line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JIT-compiled training step\n",
    "@partial(jax.jit, static_argnums=(4,))\n",
    "def train_step(state, batch, target, key, num_steps):\n",
    "    \"\"\"Single training step.\"\"\"\n",
    "    def loss_fn(params):\n",
    "        keys = jax.random.split(key, num_steps)\n",
    "        \n",
    "        def step(carry, subkey):\n",
    "            return child_nca.apply({'params': params}, carry, subkey), None\n",
    "        \n",
    "        final, _ = jax.lax.scan(step, batch, keys)\n",
    "        loss = jnp.mean((final[..., :4] - target) ** 2)\n",
    "        return loss, final\n",
    "    \n",
    "    (loss, outputs), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.params)\n",
    "    grads = normalize_gradients(grads)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    return state, loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 training loop\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: Static Formation Learning\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "phase1_losses = []\n",
    "phase1_times = []\n",
    "\n",
    "for epoch in range(PHASE1_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    key, subkey1, subkey2, subkey3 = jax.random.split(key, 4)\n",
    "    \n",
    "    # Sample from pool\n",
    "    indices, batch = pool.sample(config.batch_size, subkey1)\n",
    "    \n",
    "    # Apply damage after warmup\n",
    "    if epoch > config.damage_start_epoch:\n",
    "        batch = pool.apply_damage(batch, config.damage_samples, subkey2)\n",
    "    \n",
    "    # Random step count [64, 96]\n",
    "    num_steps = int(jax.random.randint(subkey3, (), config.min_steps, config.max_steps + 1))\n",
    "    \n",
    "    # Train step\n",
    "    state, loss, outputs = train_step(state, batch, target, subkey3, num_steps)\n",
    "    \n",
    "    # Compute per-sample losses for pool update\n",
    "    per_sample_losses = jnp.mean((outputs[..., :4] - target) ** 2, axis=(1, 2, 3))\n",
    "    \n",
    "    # Update pool\n",
    "    pool.update(indices, outputs, per_sample_losses)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    phase1_losses.append(float(loss))\n",
    "    phase1_times.append(elapsed)\n",
    "    \n",
    "    if epoch % config.log_interval == 0:\n",
    "        print(f\"Epoch {epoch:4d}: loss = {loss:.6f}, time = {elapsed:.3f}s\")\n",
    "\n",
    "print(f\"\\nPhase 1 complete. Final loss: {phase1_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Phase 1 training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(phase1_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Phase 1: Formation Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Smoothed\n",
    "window = 50\n",
    "smoothed = np.convolve(phase1_losses, np.ones(window)/window, mode='valid')\n",
    "axes[0].plot(range(window-1, len(phase1_losses)), smoothed, 'r-', alpha=0.7, label='Smoothed')\n",
    "axes[0].legend()\n",
    "\n",
    "# Time per epoch\n",
    "axes[1].plot(phase1_times)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Time (s)')\n",
    "axes[1].set_title('Phase 1: Time per Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model\n",
    "key, subkey = jax.random.split(key)\n",
    "test_state = seed\n",
    "\n",
    "# Run forward\n",
    "trajectory = [test_state]\n",
    "for i in range(100):\n",
    "    key, subkey = jax.random.split(key)\n",
    "    test_state = child_nca.apply({'params': state.params}, test_state, subkey)\n",
    "    if i % 10 == 0:\n",
    "        trajectory.append(test_state)\n",
    "\n",
    "# Visualize evolution\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, (ax, frame) in enumerate(zip(axes.flat, trajectory)):\n",
    "    ax.imshow(np.clip(frame[..., :4], 0, 1))\n",
    "    ax.set_title(f'Step {i*10}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Phase 1: Formation Evolution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Multi-Formation Transitions\n",
    "\n",
    "Train the model to switch between different formations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 2: Multi-Formation Transitions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Reset pool with trained states\n",
    "pool = NCAPool(seed, config.pool_size)\n",
    "\n",
    "# Formation names for logging\n",
    "formation_names = list(targets.keys())\n",
    "\n",
    "phase2_losses = []\n",
    "phase2_formations = []\n",
    "\n",
    "for epoch in range(min(PHASE2_EPOCHS, 500)):  # Shorter for demo\n",
    "    key, subkey1, subkey2, subkey3, subkey4 = jax.random.split(key, 5)\n",
    "    \n",
    "    # Random target formation\n",
    "    target_idx = int(jax.random.randint(subkey1, (), 0, len(formation_names)))\n",
    "    target = targets[formation_names[target_idx]]\n",
    "    \n",
    "    # Sample from pool\n",
    "    indices, batch = pool.sample(config.batch_size, subkey2)\n",
    "    \n",
    "    # Damage augmentation\n",
    "    if epoch > config.damage_start_epoch:\n",
    "        batch = pool.apply_damage(batch, config.damage_samples, subkey3)\n",
    "    \n",
    "    # Random steps\n",
    "    num_steps = int(jax.random.randint(subkey4, (), config.min_steps, config.max_steps + 1))\n",
    "    \n",
    "    # Train\n",
    "    state, loss, outputs = train_step(state, batch, target, subkey4, num_steps)\n",
    "    \n",
    "    # Update pool\n",
    "    per_sample_losses = jnp.mean((outputs[..., :4] - target) ** 2, axis=(1, 2, 3))\n",
    "    pool.update(indices, outputs, per_sample_losses)\n",
    "    \n",
    "    phase2_losses.append(float(loss))\n",
    "    phase2_formations.append(target_idx)\n",
    "    \n",
    "    if epoch % config.log_interval == 0:\n",
    "        print(f\"Epoch {epoch:4d}: loss = {loss:.6f}, target = {formation_names[target_idx]}\")\n",
    "\n",
    "print(f\"\\nPhase 2 complete. Final loss: {phase2_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Save model checkpoint\nimport pickle\nfrom pathlib import Path\n\ncheckpoint_dir = Path('checkpoints')\ncheckpoint_dir.mkdir(exist_ok=True)\n\ncheckpoint = {\n    'params': state.params,\n    'config': {\n        'grid_size': GRID_SIZE,\n        'num_channels': NUM_CHANNELS,\n        'hidden_dim': 128,\n    },\n    'metrics': {\n        'phase1_losses': phase1_losses,\n        'phase2_losses': phase2_losses,\n    }\n}\n\nwith open(checkpoint_dir / 'battle_nca_trained.pkl', 'wb') as f:\n    pickle.dump(checkpoint, f)\n\nprint(f\"Model saved to {checkpoint_dir / 'battle_nca_trained.pkl'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path('../checkpoints')\n",
    "checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "checkpoint = {\n",
    "    'params': state.params,\n",
    "    'config': {\n",
    "        'grid_size': GRID_SIZE,\n",
    "        'num_channels': NUM_CHANNELS,\n",
    "        'hidden_dim': 128,\n",
    "    },\n",
    "    'metrics': {\n",
    "        'phase1_losses': phase1_losses,\n",
    "        'phase2_losses': phase2_losses,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(checkpoint_dir / 'battle_nca_trained.pkl', 'wb') as f:\n",
    "    pickle.dump(checkpoint, f)\n",
    "\n",
    "print(f\"Model saved to {checkpoint_dir / 'battle_nca_trained.pkl'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Phase 1**: Training the NCA to grow and maintain a single formation (line)\n",
    "2. **Phase 2**: Training on multiple formations for goal-conditioned behavior\n",
    "\n",
    "**Next steps:**\n",
    "- See `02_evaluation.ipynb` for model evaluation and metrics\n",
    "- See `03_visualization.ipynb` for animations and detailed visualizations\n",
    "- For Phase 3 (combat dynamics), use the `HierarchicalNCA` with two armies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
